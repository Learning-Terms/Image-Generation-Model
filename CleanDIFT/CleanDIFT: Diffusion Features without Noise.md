# CleanDIFT: Diffusion Features without Noise
### [Arxiv](https://arxiv.org/pdf/2412.03439)   [Bili](https://www.bilibili.com/video/BV1b541197HX?buvid=XX68ACF6051B519928AE6B6F405AD2D005DC3&from_spmid=playlist.playlist-detail.0.0&is_story_h5=false&mid=DrRwFpk%2BbcbkpzyW8K9UaQ%3D%3D&plat_id=116&share_from=ugc&share_medium=android&share_plat=android&share_session_id=7ec5d6cc-eb1b-40d0-ae1d-b8d96e6a2a6f&share_source=WEIXIN&share_tag=s_i&spmid=united.player-video-detail.0.0&timestamp=1750868703&unique_k=9RxcO7z&up_id=373596439&share_source=weixin)


## Abstract
- **Internal features** from large-scale pre-trained diffusion models have recently been established as **powerful semantic descriptors** for **a wide range of downstream tasks**.
- Works that use these features generally need to **add noise to images before passing them through the model to obtain the semantic features**, as the models do not offer the most useful features when given images with little to no noise.
- We show that **this noise has a critical impact on the usefulness of these features that cannot be remedied by ensembling with different random noisesï¼ˆå™ªå£°çš„æ·»åŠ ä¸ºç‰¹å¾è´¨é‡å¸¦æ¥äº†ä¸ç¡®å®šå› ç´  æ½œåœ¨ç‰¹å¾çš„è´¨é‡å¯¹æ·»åŠ çš„å™ªå£°æ•æ„Ÿï¼‰**.
- We address this issue by **introducing a lightweight, unsupervised fine-tuning method that enables diffusion backbones to provide highquality, noise-free semantic features**.
- We show that these features readily outperform previous diffusion features by a wide margin in a wide variety of extraction setups and downstream tasks, offering better performance than even ensemble-based methods at a fraction of the cost.
------------
## æ‘˜è¦
- ğŸ“ ç ”ç©¶èƒŒæ™¯ï¼šå¤§è§„æ¨¡é¢„è®­ç»ƒæ‰©æ•£æ¨¡å‹ä¸­çš„ å†…éƒ¨ç‰¹å¾ï¼ˆintermediate featuresï¼‰è¿‘å¹´æ¥è¢«è¯æ˜å¯ä½œä¸ºå¼ºå¤§çš„è¯­ä¹‰æè¿°ç¬¦ï¼Œå¹¿æ³›ç”¨äºä¸‹æ¸¸ä»»åŠ¡ï¼ˆå¦‚å›¾åƒåˆ†ç±»ã€æ£€ç´¢ã€åˆ†å‰²ç­‰ï¼‰ã€‚
- ğŸš¨ é—®é¢˜å‘ç°ï¼šå½“å‰æå–è¿™äº›ç‰¹å¾çš„æ–¹æ³•é€šå¸¸éœ€è¦äººä¸ºç»™è¾“å…¥å›¾åƒåŠ å™ªå£°ï¼Œå› ä¸ºæ‰©æ•£æ¨¡å‹åœ¨å¤„ç†â€œå¹²å‡€å›¾åƒâ€æ—¶ï¼Œè¾“å‡ºçš„ç‰¹å¾ä¸å…·å¤‡è‰¯å¥½çš„è¯­ä¹‰è¡¨è¾¾åŠ›ã€‚**ä½†æ˜¯å™ªå£°çš„æ·»åŠ ä¸ºç‰¹å¾çš„è´¨é‡å¼•å…¥äº†ä¸ç¡®å®šæ€§ï¼Œä¸­é—´ç‰¹å¾å¯¹æ‰€æ·»åŠ çš„å™ªå£°æ•æ„Ÿ**ï¼Œå³ä½¿ä½¿ç”¨å¤šä¸ªéšæœºå™ªå£°è¿›è¡Œ ensembleï¼ˆé›†æˆï¼‰ï¼Œä¹Ÿæ— æ³•æœ‰æ•ˆè§£å†³ç‰¹å¾è´¨é‡é—®é¢˜ã€‚
- ğŸ’¡ ä½œè€…æå‡ºçš„æ–¹æ³•ï¼šæå‡ºä¸€ç§ è½»é‡çº§çš„ã€æ— ç›‘ç£çš„ fine-tuning æ–¹æ³•ï¼Œå¯¹ diffusion backbone è¿›è¡Œå¾®è°ƒï¼Œä½¿å…¶åœ¨ æ— å™ªå£°è¾“å…¥ä¸‹ä¹Ÿèƒ½è¾“å‡ºé«˜è´¨é‡çš„è¯­ä¹‰ç‰¹å¾ã€‚
- ğŸ“ˆ æ•ˆæœä¸è´¡çŒ®ï¼šè¯¥æ–¹æ³•åœ¨å¤šç§ç‰¹å¾æå–åœºæ™¯å’Œä¸‹æ¸¸ä»»åŠ¡ä¸­ï¼Œæ˜¾è‘—ä¼˜äºåŸå§‹çš„æ‰©æ•£ç‰¹å¾ï¼ˆå³å¸¦å™ªå£°æå–çš„ç‰¹å¾ï¼‰ã€‚å¹¶ä¸”ä¸ä¾èµ– ensemble æŠ€æœ¯ï¼Œè€Œåœ¨æ•ˆæœä¸Šä¼˜äº ensemble æ–¹æ³•ï¼Œä¸”è®¡ç®—æˆæœ¬æ›´ä½ã€‚
-------------
## æŠ€æœ¯æœ¯è¯­ä¸ç†è®ºè§£é‡Š
### ğŸŒ€ Diffusion Modelsï¼ˆæ‰©æ•£æ¨¡å‹ï¼‰
- æ‰©æ•£æ¨¡å‹æ˜¯ä¸€ç±»ç”Ÿæˆæ¨¡å‹ï¼Œå…¶è®­ç»ƒæµç¨‹åŒ…æ‹¬ï¼š
  - æ­£å‘è¿‡ç¨‹ï¼ˆForward Processï¼‰ï¼šé€æ­¥å¾€å›¾åƒä¸­æ·»åŠ é«˜æ–¯å™ªå£°
  - åå‘è¿‡ç¨‹ï¼ˆReverse Processï¼‰ï¼šé€šè¿‡ç¥ç»ç½‘ç»œå­¦ä¹ å¦‚ä½•é€æ­¥å»å™ªï¼Œè¿˜åŸåŸå§‹å›¾åƒ
  - DDPMï¼šDenoising Diffusion Probabilistic Models (Ho et al., 2020)

### ğŸ¯ Intermediate Semantic Featuresï¼ˆä¸­é—´è¯­ä¹‰ç‰¹å¾ï¼‰
- åœ¨æ‰©æ•£æ¨¡å‹ä¸­ï¼Œç‰¹å¾é€šå¸¸æŒ‡ U-Net ç½‘ç»œç»“æ„ä¸­ä¸åŒå±‚çš„ä¸­é—´è¾“å‡ºã€‚
- ç ”ç©¶å‘ç°ï¼Œè¿™äº›ä¸­é—´ç‰¹å¾èƒ½**æœ‰æ•ˆç¼–ç ï¼ˆä½“ç°ï¼‰è¾“å…¥å›¾åƒçš„é«˜å±‚è¯­ä¹‰ä¿¡æ¯**ï¼Œä¸ CLIP ç­‰æ¨¡å‹ä¸­çš„â€œå›¾åƒåµŒå…¥â€æœ‰ç±»ä¼¼ç”¨é€”ã€‚

### âŒ ä¸ºä»€ä¹ˆéœ€è¦åŠ å™ªå£°æ‰èƒ½æå–è¯­ä¹‰ç‰¹å¾ï¼Ÿ
- æ‰©æ•£æ¨¡å‹çš„ U-Net é€šå¸¸æ˜¯ä¸ºâ€œå™ªå£°è¾“å…¥â€è®¾è®¡çš„ï¼Œå› æ­¤åœ¨è¾“å…¥å›¾åƒå‡ ä¹æ²¡æœ‰å™ªå£°æ—¶ï¼Œå…¶å¤„ç†æ–¹å¼**ä¸è®­ç»ƒé˜¶æ®µå­˜åœ¨åˆ†å¸ƒåå·®ï¼ˆdistribution shiftï¼‰**ï¼Œå¯¼è‡´ï¼š
  - ç‰¹å¾è¡¨è¾¾å¼±
  - æ¨¡å‹æ¿€æ´»ä¸å……åˆ†
- åŠ å™ªå£°æ˜¯äººä¸ºâ€œæ¨¡æ‹Ÿè®­ç»ƒæ—¶çš„è¾“å…¥â€ï¼Œ**ä½†è¿™ä¼šå¼•å…¥ä¸ç¨³å®šæ€§ï¼ˆå¯¹éšæœºå™ªå£°æ•æ„Ÿï¼‰**

### ğŸ› ï¸ ä½œè€…æå‡ºçš„ Unsupervised Fine-tuning æ–¹æ³•
- æ— éœ€æ ‡æ³¨æ•°æ®ï¼Œé€šè¿‡è°ƒæ•´æ‰©æ•£æ¨¡å‹å‚æ•°ï¼Œä½¿å…¶åœ¨â€œæ— å™ªå£°è¾“å…¥â€ä¸‹ä¹Ÿèƒ½æå–é«˜è´¨é‡è¯­ä¹‰ç‰¹å¾ã€‚
- ç‰¹ç‚¹ï¼š
  - è½»é‡ï¼šå¾®è°ƒå‚æ•°é‡è¾ƒå°
  - æ— ç›‘ç£ï¼šæ— éœ€ä¸‹æ¸¸ä»»åŠ¡çš„æ ‡ç­¾
  - æ•ˆç‡é«˜ï¼šå»é™¤ ensemble å¸¦æ¥çš„å†—ä½™è®¡ç®—
